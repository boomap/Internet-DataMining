### 第二次 0928

#### 文档表示

* 元描述

  优点：依赖人工标注，结果可靠、基于受控词汇的检索很高效

  不足：人工标注非常耗时、检索收限制

  * 域信息（author, title, date）
  * 关键词、受控词汇
  * 分类

* 自动文档表示

  * **词袋：**由一篇文档中出现的词的集合所表示

    丢失了语法信息

    大多数情况不需要语义关系

    符号化：识别词的边界

    * 词语形态规范化、词根(Stemming)：删除形态信息

    * 词形还原(Lemmatization)：将词变成语法原型

    停用词：大幅减少索引大小

    **大多数互联网搜索引擎不使用stemming/lemmatization**

    无法从词袋表示恢复原文档

  * **密集向量(Dense Vector)：**

    转化方法

    1. 基于词向量的平均（Word2Vec，BERT）
    2. 基于句子向量的平均（基于词向量，CNN，LSTM，BERT）
    3. 直接获取：类似句子向量求解，考虑篇章结构

* 文档索引

  * 倒排索引
  * 相关度与相似性
  * 布尔模型
    * 优点：简单，对查询结果严格控制
    * 防：耗时耗力

* 向量空间模型：比较常用

  向量空间中的相似性，相似性的计算应该考虑文档长度

  * 文档长度规范化：除以文章的总词数。规范化内积。
  * tf：考虑词频 & idf：考虑词在当前文档中的信息量
  * 其他相似性度量

* 概率检索模型



#### 第三次 1012

* Web页面采集流程与策略

* Web页面排序

* 连接分析经典算法

  * HITS：考虑两类页面（内容页与枢纽页）

    * 权威值&枢纽值

  * PageRank

    随机游走模型

    排序泄露、排序沉入

  * 改进-RWR：任意两个节点之间都加上一个通路，相当于在原始的矩阵中加上$1-\alpha $的值

* 基于学习的网页排序：Learning to Rank



#### 第四次：自然语言处理 10.19

* 基本方法

  * 理性主义方法
  * 经验主义方法
  * 融合方法

* 分词方法

  * 简单的模式匹配

    * 正向最大匹配FMM

    * 逆向最大匹配BMM

    * 双向匹配BM

      比较FMM法与BMM法的切分结果，从而决定正确的切分

      （大颗粒度词越多越好，非词典词和单字词越少越好）

  * 基于规则的方法

    * 最少分词

  * 基于统计的方法

    * 语言统计模型分析

  * ==基于统计的词网格分词？==

    1. 候选词网络构造：利用词典匹配，列举输入句子所有可能的切分词语，并以词网格形式保存
    2. 计算词网格中每条路径权值
    3. 根据图搜索算法在图中找到一条权值最大的路径，作为最后分词的结果

  * 基于字分类的分词：赋予每个汉字一个相对于词的位置类别（利用统计模型获得最优的类别序列）

* 词性标注：为句子中每个词标注词性，对后续句法分析、词义消歧等任务非常有用

  * 基于规则：人工基于词汇与其它语言知识构建标注规则

  * 基于学习：基于人工标注语料进行训练

    看成序列标注问题

* 句法分析